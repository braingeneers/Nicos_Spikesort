{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\" size=7>Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the source code that runs the `spikesort_easy` application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">This code is based on [this repository](https://github.com/flatironinstitute/spikeforest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color=\"red\">Siddish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\"> Finish this notebook so that you can create a functioning application inside the `Welcome to spikesort_easy` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'login' is not a git command. See 'git --help'.\r\n",
      "\r\n",
      "The most similar command is\r\n",
      "\tcolumn\r\n"
     ]
    }
   ],
   "source": [
    "!git login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/braingeneers/dashboard ./dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dashboard.apps.utils import NumpyS3Memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tenacity\n",
    "#!pip install smart_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import kachery as ka\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "#do things to get braingeneers data\n",
    "#install(\"git+https://github.com/braingeneers/braingeneerspy.git\")\n",
    "#install(\"matplotlib\")\n",
    "import hither_sf as hither\n",
    "from spikeforest2 import sorters\n",
    "import matplotlib\n",
    "import braingeneers.datasets_electrophysiology\n",
    "import spikeinterface.extractors as se #for mda conversion only\n",
    "import spiketoolkit as st\n",
    "import braingeneers\n",
    "from braingeneers import datasets_electrophysiology as ephys\n",
    "import numpy as np\n",
    "import json\n",
    "import spikeforest2_utils\n",
    "from spikeforest2_utils import AutoRecordingExtractor, MdaRecordingExtractor\n",
    "import hither_sf as hither\n",
    "import kachery as ka\n",
    "import io\n",
    "import sys\n",
    "spikeforest2_utils.__version__=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "folders = !ls\n",
    "if \"kach_dir\" not in folders:\n",
    "    !mkdir kach_dir\n",
    "    !touch kach_dir/raw.mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_dir = ! pwd\n",
    "kach_dir = current_dir[0] + \"/kach_dir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Choose Experiment, time range, channels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">choose time range, experiment name, experiment num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.environ['KACHERY_STORAGE_DIR']=kach_dir\n",
    "#batch_uuid = '2020-11-27-e-UCSF-axionplate' \n",
    "#experiment_num= 9 #arpitha make this a button to choose exp num\n",
    "#start = 1 #arpitha, sliders here for start minutes\n",
    "#stop = 5 #and end minutes\n",
    "#recording_path = 'sha1://961f4a641af64dded4821610189f808f0192de4d/SYNTH_MEAREC_TETRODE/synth_mearec_tetrode_noise10_K10_C4/002_synth.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-02 01:07:54   70850128 well_A1_chan_group_idx_10_time_000.npy\r\n",
      "2020-12-02 01:25:17   41550128 well_A1_chan_group_idx_10_time_001.npy\r\n",
      "2020-12-02 01:07:54   70850128 well_A1_chan_group_idx_11_time_000.npy\r\n",
      "2020-12-02 01:25:18   41550128 well_A1_chan_group_idx_11_time_001.npy\r\n",
      "2020-12-02 01:07:56   70850128 well_A1_chan_group_idx_12_time_000.npy\r\n",
      "2020-12-02 01:25:20   41550128 well_A1_chan_group_idx_12_time_001.npy\r\n",
      "2020-12-02 01:07:54   70850128 well_A1_chan_group_idx_13_time_000.npy\r\n",
      "2020-12-02 01:25:18   41550128 well_A1_chan_group_idx_13_time_001.npy\r\n",
      "2020-12-02 01:07:54   70850128 well_A1_chan_group_idx_14_time_000.npy\r\n",
      "2020-12-02 01:25:18   41550128 well_A1_chan_group_idx_14_time_001.npy\r\n",
      "2020-12-02 01:08:02   70850128 well_A1_chan_group_idx_1_time_000.npy\r\n",
      "2020-12-02 01:25:22   41550128 well_A1_chan_group_idx_1_time_001.npy\r\n",
      "2020-12-02 01:08:02   70850128 well_A1_chan_group_idx_2_time_000.npy\r\n",
      "2020-12-02 01:25:22   41550128 well_A1_chan_group_idx_2_time_001.npy\r\n",
      "2020-12-02 01:08:02   70850128 well_A1_chan_group_idx_3_time_000.npy\r\n",
      "2020-12-02 01:25:22   41550128 well_A1_chan_group_idx_3_time_001.npy\r\n",
      "2020-12-02 01:08:04   70850128 well_A1_chan_group_idx_4_time_000.npy\r\n",
      "2020-12-02 01:25:24   41550128 well_A1_chan_group_idx_4_time_001.npy\r\n",
      "2020-12-02 01:08:02   70850128 well_A1_chan_group_idx_5_time_000.npy\r\n",
      "2020-12-02 01:25:23   41550128 well_A1_chan_group_idx_5_time_001.npy\r\n",
      "2020-12-02 01:08:08   70850128 well_A1_chan_group_idx_6_time_000.npy\r\n",
      "2020-12-02 01:25:26   41550128 well_A1_chan_group_idx_6_time_001.npy\r\n",
      "2020-12-02 01:08:09   70850128 well_A1_chan_group_idx_7_time_000.npy\r\n",
      "2020-12-02 01:25:28   41550128 well_A1_chan_group_idx_7_time_001.npy\r\n",
      "2020-12-02 01:08:11   70850128 well_A1_chan_group_idx_8_time_000.npy\r\n",
      "2020-12-02 01:25:25   41550128 well_A1_chan_group_idx_8_time_001.npy\r\n",
      "2020-12-02 01:08:10   70850128 well_A1_chan_group_idx_9_time_000.npy\r\n",
      "2020-12-02 01:25:27   41550128 well_A1_chan_group_idx_9_time_001.npy\r\n",
      "2020-12-02 01:08:12   70850128 well_A2_chan_group_idx_10_time_000.npy\r\n",
      "2020-12-02 01:25:27   41550128 well_A2_chan_group_idx_10_time_001.npy\r\n",
      "2020-12-02 01:08:14   70850128 well_A2_chan_group_idx_11_time_000.npy\r\n",
      "2020-12-02 01:25:31   41550128 well_A2_chan_group_idx_11_time_001.npy\r\n",
      "2020-12-02 01:08:15   70850128 well_A2_chan_group_idx_12_time_000.npy\r\n",
      "2020-12-02 01:25:31   41550128 well_A2_chan_group_idx_12_time_001.npy\r\n",
      "2020-12-02 01:08:17   70850128 well_A2_chan_group_idx_13_time_000.npy\r\n",
      "2020-12-02 01:25:33   41550128 well_A2_chan_group_idx_13_time_001.npy\r\n",
      "2020-12-02 01:08:16   70850128 well_A2_chan_group_idx_14_time_000.npy\r\n",
      "2020-12-02 01:25:33   41550128 well_A2_chan_group_idx_14_time_001.npy\r\n",
      "2020-12-02 01:08:18   70850128 well_A2_chan_group_idx_15_time_000.npy\r\n",
      "2020-12-02 01:25:34   41550128 well_A2_chan_group_idx_15_time_001.npy\r\n",
      "2020-12-02 01:08:21   70850128 well_A2_chan_group_idx_1_time_000.npy\r\n",
      "2020-12-02 01:25:36   41550128 well_A2_chan_group_idx_1_time_001.npy\r\n",
      "2020-12-02 01:08:22   70850128 well_A2_chan_group_idx_2_time_000.npy\r\n",
      "2020-12-02 01:25:36   41550128 well_A2_chan_group_idx_2_time_001.npy\r\n",
      "2020-12-02 01:08:24   70850128 well_A2_chan_group_idx_3_time_000.npy\r\n",
      "2020-12-02 01:25:37   41550128 well_A2_chan_group_idx_3_time_001.npy\r\n",
      "2020-12-02 01:08:24   70850128 well_A2_chan_group_idx_4_time_000.npy\r\n",
      "2020-12-02 01:25:38   41550128 well_A2_chan_group_idx_4_time_001.npy\r\n",
      "2020-12-02 01:08:25   70850128 well_A2_chan_group_idx_5_time_000.npy\r\n",
      "2020-12-02 01:25:37   41550128 well_A2_chan_group_idx_5_time_001.npy\r\n",
      "2020-12-02 01:08:28   70850128 well_A2_chan_group_idx_6_time_000.npy\r\n",
      "2020-12-02 01:25:40   41550128 well_A2_chan_group_idx_6_time_001.npy\r\n",
      "2020-12-02 01:08:28   70850128 well_A2_chan_group_idx_7_time_000.npy\r\n",
      "2020-12-02 01:25:43   41550128 well_A2_chan_group_idx_7_time_001.npy\r\n",
      "2020-12-02 01:08:30   70850128 well_A2_chan_group_idx_8_time_000.npy\r\n",
      "2020-12-02 01:25:41   41550128 well_A2_chan_group_idx_8_time_001.npy\r\n",
      "2020-12-02 01:08:32   70850128 well_A2_chan_group_idx_9_time_000.npy\r\n",
      "2020-12-02 01:25:41   41550128 well_A2_chan_group_idx_9_time_001.npy\r\n",
      "2020-12-02 01:08:33   70850128 well_A3_chan_group_idx_10_time_000.npy\r\n",
      "2020-12-02 01:25:43   41550128 well_A3_chan_group_idx_10_time_001.npy\r\n",
      "2020-12-02 01:08:34   70850128 well_A3_chan_group_idx_11_time_000.npy\r\n",
      "2020-12-02 01:25:45   41550128 well_A3_chan_group_idx_11_time_001.npy\r\n",
      "2020-12-02 01:08:36   70850128 well_A3_chan_group_idx_12_time_000.npy\r\n",
      "2020-12-02 01:25:46   41550128 well_A3_chan_group_idx_12_time_001.npy\r\n",
      "2020-12-02 01:08:37   70850128 well_A3_chan_group_idx_13_time_000.npy\r\n",
      "2020-12-02 01:25:46   41550128 well_A3_chan_group_idx_13_time_001.npy\r\n",
      "2020-12-02 01:08:37   70850128 well_A3_chan_group_idx_14_time_000.npy\r\n",
      "2020-12-02 01:25:46   41550128 well_A3_chan_group_idx_14_time_001.npy\r\n",
      "2020-12-02 01:08:37   70850128 well_A3_chan_group_idx_15_time_000.npy\r\n",
      "2020-12-02 01:25:47   41550128 well_A3_chan_group_idx_15_time_001.npy\r\n",
      "2020-12-02 01:08:42   70850128 well_A3_chan_group_idx_16_time_000.npy\r\n",
      "2020-12-02 01:25:50   41550128 well_A3_chan_group_idx_16_time_001.npy\r\n",
      "2020-12-02 01:08:42   70850128 well_A3_chan_group_idx_1_time_000.npy\r\n",
      "2020-12-02 01:25:51   41550128 well_A3_chan_group_idx_1_time_001.npy\r\n",
      "2020-12-02 01:08:43   70850128 well_A3_chan_group_idx_2_time_000.npy\r\n",
      "2020-12-02 01:25:50   41550128 well_A3_chan_group_idx_2_time_001.npy\r\n",
      "2020-12-02 01:08:44   70850128 well_A3_chan_group_idx_3_time_000.npy\r\n",
      "2020-12-02 01:25:51   41550128 well_A3_chan_group_idx_3_time_001.npy\r\n",
      "2020-12-02 01:08:45   70850128 well_A3_chan_group_idx_4_time_000.npy\r\n",
      "2020-12-02 01:25:51   41550128 well_A3_chan_group_idx_4_time_001.npy\r\n",
      "2020-12-02 01:08:48   70850128 well_A3_chan_group_idx_5_time_000.npy\r\n",
      "2020-12-02 01:25:53   41550128 well_A3_chan_group_idx_5_time_001.npy\r\n",
      "2020-12-02 01:08:48   70850128 well_A3_chan_group_idx_6_time_000.npy\r\n",
      "2020-12-02 01:25:53   41550128 well_A3_chan_group_idx_6_time_001.npy\r\n",
      "2020-12-02 01:08:49   70850128 well_A3_chan_group_idx_7_time_000.npy\r\n",
      "2020-12-02 01:25:54   41550128 well_A3_chan_group_idx_7_time_001.npy\r\n",
      "2020-12-02 01:08:50   70850128 well_A3_chan_group_idx_8_time_000.npy\r\n",
      "2020-12-02 01:25:54   41550128 well_A3_chan_group_idx_8_time_001.npy\r\n",
      "2020-12-02 01:08:52   70850128 well_A3_chan_group_idx_9_time_000.npy\r\n",
      "2020-12-02 01:25:55   41550128 well_A3_chan_group_idx_9_time_001.npy\r\n",
      "2020-12-02 01:08:56   70850128 well_B1_chan_group_idx_10_time_000.npy\r\n",
      "2020-12-02 01:25:56   41550128 well_B1_chan_group_idx_10_time_001.npy\r\n",
      "2020-12-02 01:08:56   70850128 well_B1_chan_group_idx_11_time_000.npy\r\n",
      "2020-12-02 01:25:59   41550128 well_B1_chan_group_idx_11_time_001.npy\r\n",
      "2020-12-02 01:08:56   70850128 well_B1_chan_group_idx_12_time_000.npy\r\n",
      "2020-12-02 01:25:57   41550128 well_B1_chan_group_idx_12_time_001.npy\r\n",
      "2020-12-02 01:08:57   70850128 well_B1_chan_group_idx_13_time_000.npy\r\n",
      "2020-12-02 01:25:59   41550128 well_B1_chan_group_idx_13_time_001.npy\r\n",
      "2020-12-02 01:08:57   70850128 well_B1_chan_group_idx_14_time_000.npy\r\n",
      "2020-12-02 01:25:59   41550128 well_B1_chan_group_idx_14_time_001.npy\r\n",
      "2020-12-02 01:09:02   70850128 well_B1_chan_group_idx_15_time_000.npy\r\n",
      "2020-12-02 01:26:00   41550128 well_B1_chan_group_idx_15_time_001.npy\r\n",
      "2020-12-02 01:09:01   70850128 well_B1_chan_group_idx_16_time_000.npy\r\n",
      "2020-12-02 01:26:02   41550128 well_B1_chan_group_idx_16_time_001.npy\r\n",
      "2020-12-02 01:09:01   70850128 well_B1_chan_group_idx_1_time_000.npy\r\n",
      "2020-12-02 01:26:02   41550128 well_B1_chan_group_idx_1_time_001.npy\r\n",
      "2020-12-02 01:09:04   70850128 well_B1_chan_group_idx_2_time_000.npy\r\n",
      "2020-12-02 01:26:02   41550128 well_B1_chan_group_idx_2_time_001.npy\r\n",
      "2020-12-02 01:09:03   70850128 well_B1_chan_group_idx_3_time_000.npy\r\n",
      "2020-12-02 01:26:03   41550128 well_B1_chan_group_idx_3_time_001.npy\r\n",
      "2020-12-02 01:09:08   70850128 well_B1_chan_group_idx_4_time_000.npy\r\n",
      "2020-12-02 01:26:04   41550128 well_B1_chan_group_idx_4_time_001.npy\r\n",
      "2020-12-02 01:09:08   70850128 well_B1_chan_group_idx_5_time_000.npy\r\n",
      "2020-12-02 01:26:06   41550128 well_B1_chan_group_idx_5_time_001.npy\r\n",
      "2020-12-02 01:09:10   70850128 well_B1_chan_group_idx_6_time_000.npy\r\n",
      "2020-12-02 01:26:05   41550128 well_B1_chan_group_idx_6_time_001.npy\r\n",
      "2020-12-02 01:09:10   70850128 well_B1_chan_group_idx_7_time_000.npy\r\n",
      "2020-12-02 01:26:06   41550128 well_B1_chan_group_idx_7_time_001.npy\r\n",
      "2020-12-02 01:09:11   70850128 well_B1_chan_group_idx_8_time_000.npy\r\n",
      "2020-12-02 01:26:08   41550128 well_B1_chan_group_idx_8_time_001.npy\r\n",
      "2020-12-02 01:09:14   70850128 well_B1_chan_group_idx_9_time_000.npy\r\n",
      "2020-12-02 01:26:08   41550128 well_B1_chan_group_idx_9_time_001.npy\r\n",
      "2020-12-02 01:09:14   70850128 well_B2_chan_group_idx_10_time_000.npy\r\n",
      "2020-12-02 01:26:10   41550128 well_B2_chan_group_idx_10_time_001.npy\r\n",
      "2020-12-02 01:09:17   70850128 well_B2_chan_group_idx_11_time_000.npy\r\n",
      "2020-12-02 01:26:10   41550128 well_B2_chan_group_idx_11_time_001.npy\r\n",
      "2020-12-02 01:09:16   70850128 well_B2_chan_group_idx_12_time_000.npy\r\n",
      "2020-12-02 01:26:09   41550128 well_B2_chan_group_idx_12_time_001.npy\r\n",
      "2020-12-02 01:09:16   70850128 well_B2_chan_group_idx_13_time_000.npy\r\n",
      "2020-12-02 01:26:12   41550128 well_B2_chan_group_idx_13_time_001.npy\r\n",
      "2020-12-02 01:09:20   70850128 well_B2_chan_group_idx_14_time_000.npy\r\n",
      "2020-12-02 01:26:12   41550128 well_B2_chan_group_idx_14_time_001.npy\r\n",
      "2020-12-02 01:09:22   70850128 well_B2_chan_group_idx_15_time_000.npy\r\n",
      "2020-12-02 01:26:13   41550128 well_B2_chan_group_idx_15_time_001.npy\r\n",
      "2020-12-02 01:09:21   70850128 well_B2_chan_group_idx_16_time_000.npy\r\n",
      "2020-12-02 01:26:15   41550128 well_B2_chan_group_idx_16_time_001.npy\r\n",
      "2020-12-02 01:09:24   70850128 well_B2_chan_group_idx_1_time_000.npy\r\n",
      "2020-12-02 01:26:15   41550128 well_B2_chan_group_idx_1_time_001.npy\r\n",
      "2020-12-02 01:09:25   70850128 well_B2_chan_group_idx_2_time_000.npy\r\n",
      "2020-12-02 01:26:15   41550128 well_B2_chan_group_idx_2_time_001.npy\r\n",
      "2020-12-02 01:09:27   70850128 well_B2_chan_group_idx_3_time_000.npy\r\n",
      "2020-12-02 01:26:16   41550128 well_B2_chan_group_idx_3_time_001.npy\r\n",
      "2020-12-02 01:09:30   70850128 well_B2_chan_group_idx_4_time_000.npy\r\n",
      "2020-12-02 01:26:17   41550128 well_B2_chan_group_idx_4_time_001.npy\r\n",
      "2020-12-02 01:09:32   70850128 well_B2_chan_group_idx_5_time_000.npy\r\n",
      "2020-12-02 01:26:18   41550128 well_B2_chan_group_idx_5_time_001.npy\r\n",
      "2020-12-02 01:09:32   70850128 well_B2_chan_group_idx_6_time_000.npy\r\n",
      "2020-12-02 01:26:18   41550128 well_B2_chan_group_idx_6_time_001.npy\r\n",
      "2020-12-02 01:09:33   70850128 well_B2_chan_group_idx_7_time_000.npy\r\n",
      "2020-12-02 01:26:19   41550128 well_B2_chan_group_idx_7_time_001.npy\r\n",
      "2020-12-02 01:09:36   70850128 well_B2_chan_group_idx_8_time_000.npy\r\n",
      "2020-12-02 01:26:21   41550128 well_B2_chan_group_idx_8_time_001.npy\r\n",
      "2020-12-02 01:09:37   70850128 well_B2_chan_group_idx_9_time_000.npy\r\n",
      "2020-12-02 01:26:22   41550128 well_B2_chan_group_idx_9_time_001.npy\r\n",
      "2020-12-02 01:09:39   70850128 well_B3_chan_group_idx_10_time_000.npy\r\n",
      "2020-12-02 01:26:21   41550128 well_B3_chan_group_idx_10_time_001.npy\r\n",
      "2020-12-02 01:09:38   70850128 well_B3_chan_group_idx_11_time_000.npy\r\n",
      "2020-12-02 01:26:22   41550128 well_B3_chan_group_idx_11_time_001.npy\r\n",
      "2020-12-02 01:09:40   70850128 well_B3_chan_group_idx_12_time_000.npy\r\n",
      "2020-12-02 01:26:23   41550128 well_B3_chan_group_idx_12_time_001.npy\r\n",
      "2020-12-02 01:09:44   70850128 well_B3_chan_group_idx_13_time_000.npy\r\n",
      "2020-12-02 01:26:26   41550128 well_B3_chan_group_idx_13_time_001.npy\r\n",
      "2020-12-02 01:09:44   70850128 well_B3_chan_group_idx_14_time_000.npy\r\n",
      "2020-12-02 01:26:28   41550128 well_B3_chan_group_idx_14_time_001.npy\r\n",
      "2020-12-02 01:09:44   70850128 well_B3_chan_group_idx_15_time_000.npy\r\n",
      "2020-12-02 01:26:30   41550128 well_B3_chan_group_idx_15_time_001.npy\r\n",
      "2020-12-02 01:09:45   70850128 well_B3_chan_group_idx_16_time_000.npy\r\n",
      "2020-12-02 01:26:27   41550128 well_B3_chan_group_idx_16_time_001.npy\r\n",
      "2020-12-02 01:09:46   70850128 well_B3_chan_group_idx_1_time_000.npy\r\n",
      "2020-12-02 01:26:28   41550128 well_B3_chan_group_idx_1_time_001.npy\r\n",
      "2020-12-02 01:09:50   70850128 well_B3_chan_group_idx_2_time_000.npy\r\n",
      "2020-12-02 01:26:32   41550128 well_B3_chan_group_idx_2_time_001.npy\r\n",
      "2020-12-02 01:09:49   70850128 well_B3_chan_group_idx_3_time_000.npy\r\n",
      "2020-12-02 01:26:33   41550128 well_B3_chan_group_idx_3_time_001.npy\r\n",
      "2020-12-02 01:09:51   70850128 well_B3_chan_group_idx_4_time_000.npy\r\n",
      "2020-12-02 01:26:33   41550128 well_B3_chan_group_idx_4_time_001.npy\r\n",
      "2020-12-02 01:09:51   70850128 well_B3_chan_group_idx_5_time_000.npy\r\n",
      "2020-12-02 01:26:33   41550128 well_B3_chan_group_idx_5_time_001.npy\r\n",
      "2020-12-02 01:09:52   70850128 well_B3_chan_group_idx_6_time_000.npy\r\n",
      "2020-12-02 01:26:33   41550128 well_B3_chan_group_idx_6_time_001.npy\r\n",
      "2020-12-02 01:09:54   70850128 well_B3_chan_group_idx_7_time_000.npy\r\n",
      "2020-12-02 01:26:37   41550128 well_B3_chan_group_idx_7_time_001.npy\r\n",
      "2020-12-02 01:09:54   70850128 well_B3_chan_group_idx_8_time_000.npy\r\n",
      "2020-12-02 01:26:37   41550128 well_B3_chan_group_idx_8_time_001.npy\r\n",
      "2020-12-02 01:09:54   70850128 well_B3_chan_group_idx_9_time_000.npy\r\n",
      "2020-12-02 01:26:37   41550128 well_B3_chan_group_idx_9_time_001.npy\r\n"
     ]
    }
   ],
   "source": [
    "!aws --endpoint https://s3.nautilus.optiputer.net s3 ls s3://braingeneersdev/ephys/2020-11-27-e-primary-axion-Afternoon1/numpy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-02 01:08:02   70850128 well_A1_chan_group_idx_3_time_000.npy\r\n"
     ]
    }
   ],
   "source": [
    "!aws --endpoint https://s3.nautilus.optiputer.net s3 ls s3://braingeneersdev/ephys/2020-11-27-e-primary-axion-Afternoon1/numpy/well_A1_chan_group_idx_3_time_000.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_numpy = \"s3://braingeneersdev/ephys/2020-11-27-e-primary-axion-Afternoon1/numpy/well_A2_chan_group_idx_10_time_001.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export ENDPOINT_URL=https://s3.nautilus.optiputer.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ENDPOINT_URL'] = \"https://s3.nautilus.optiputer.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import functools\n",
    "from smart_open import open\n",
    "open = functools.partial(open, transport_params={'resource_kwargs':{'endpoint_url': os.environ['ENDPOINT_URL']}})  # wraps open setting a default endpoint_url\n",
    "#data = NumpyS3Memmap('s3://braingeneersdev/dfparks/test/test.npy')\n",
    "data = NumpyS3Memmap(this_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2596875, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:dashboard.apps.utils:4 separate requests to S3 are being performed for this slice.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.3878893e-07,  7.1303202e-07, -6.0333480e-07, -1.5906099e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=10):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, frame.filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using open now works with the PRP exactly the same way it does if the file is local\n",
    "#with open('s3://braingeneersdev/dfparks/test/hello.txt', 'r') as f:\n",
    "#with open(this_numpy, 'r') as f:\n",
    "#    print(\"sh\")\n",
    "#Hello World!\n",
    "# Example using open with a local file, identical to the S3 case\n",
    "#with open('/tmp/hello.txt', 'r') as f:\n",
    "#    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from apps.utils import NumpyS3Memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 lines\n",
      "#1: /opt/conda/lib/python3.8/site-packages/simplejson/decoder.py:400: 4.4 KiB\n",
      "    return self.scan_once(s, idx=_w(s, idx).end())\n",
      "#2: /opt/conda/lib/python3.8/site-packages/tornado/gen.py:251: 2.5 KiB\n",
      "    future.add_done_callback(lambda _: runner)\n",
      "#3: /opt/conda/lib/python3.8/site-packages/tornado/gen.py:216: 2.2 KiB\n",
      "    result = ctx_run(func, *args, **kwargs)\n",
      "#4: /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1580: 2.2 KiB\n",
      "    user_ns_hidden.update(vdict)\n",
      "#5: /opt/conda/lib/python3.8/enum.py:315: 1.7 KiB\n",
      "    return cls.__new__(cls, value)\n",
      "#6: /opt/conda/lib/python3.8/asyncio/base_events.py:739: 1.5 KiB\n",
      "    handle = events.Handle(callback, args, self, context)\n",
      "#7: /opt/conda/lib/python3.8/site-packages/IPython/core/compilerop.py:101: 1.2 KiB\n",
      "    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\n",
      "#8: /opt/conda/lib/python3.8/site-packages/tornado/gen.py:147: 1.2 KiB\n",
      "    future = Future()  # type: Future\n",
      "#9: /opt/conda/lib/python3.8/signal.py:30: 1.1 KiB\n",
      "    return enum_klass(value)\n",
      "#10: /opt/conda/lib/python3.8/site-packages/zmq/utils/jsonapi.py:43: 1.1 KiB\n",
      "    s = s.encode('utf8')\n",
      "82 other: 25.0 KiB\n",
      "Total allocated size: 44.2 KiB\n"
     ]
    }
   ],
   "source": [
    "snapshot = tracemalloc.take_snapshot()\n",
    "display_top(snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view other experiment numbers in the same batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data, time array (seconds), and sampling freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2596875, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X, t, fs = ephys.load_blocks(batch_uuid, experiment_num, start=start, stop=stop)\n",
    "X = data\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 22000 #????\n",
    "#X = X.T #spikeinterface wants it MxN (channel number by time)\n",
    "X.shape\n",
    "\n",
    "Y = np.append(X[:,0:1], X[:,1:2], axis=1)\n",
    "#Z = np.append(X[:,2:3], X[:,3:4], axis=1)\n",
    "Y = Y.T\n",
    "\n",
    "#M = np.append(Y,Z,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M = M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2596875)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2596875)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is sampling Freq:  22000\n"
     ]
    }
   ],
   "source": [
    "print(\"this is sampling Freq: \", fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">optionally (ideally): apply geometry for locations of electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_chan = X[selected_channels[0],:]\n",
    "# print(\"last_chan shape \", last_chan.shape)\n",
    "# print(\"X[0].shape \", X[0].shape)\n",
    "\n",
    "\n",
    "#geom = np.zeros((X.shape[1],2))\n",
    "#geom = np.zeros((1,2)) # initialize recording device geometry to zeros\n",
    "\n",
    "# if len(selected_channels)==1:\n",
    "#     this_chan = X[selected_channels[0]]\n",
    "#     this_chan = np.array([this_chan])\n",
    "#     X = this_chan\n",
    "#     print(\"1 chan: \", X.shape)\n",
    "    \n",
    "    \n",
    "# if len(selected_channels)==2:\n",
    "#     X = np.append([X[selected_channels[0]]], [X[selected_channels[1]]], axis=0)\n",
    "#     print(\"2 chan: \", X.shape)\n",
    "#     geom = np.array([[0.0,0.0],[0.0,1.0]])\n",
    "\n",
    "# if len(selected_channels)>2: #PROBLEMATIC\n",
    "#     for chan in range(1,len(selected_channels)):\n",
    "#         last_chan = np.append([last_chan],[X[selected_channels[chan]]],axis=0)\n",
    "#     X = last_chan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2596875)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minutes =  1.515151515151515e-06\n"
     ]
    }
   ],
   "source": [
    "#X.shape\n",
    "#X[1:10,1:10]\n",
    "print(\"minutes = \", X.shape[0]/fs/60)\n",
    "#print(\"expected minutes =\", stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only two channels, so Geom always two points 1 unit apart.\n"
     ]
    }
   ],
   "source": [
    "if X.shape[0] == 2 :\n",
    "    geom = np.array([[0.0,0.0],[0.0,1.0]])\n",
    "    print(\"only two channels, so Geom always two points 1 unit apart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geom.shape #the 2d locations in space of each channel on the recording device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"Recording\" for spikeForest and Filter recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording=se.NumpyRecordingExtractor(\n",
    "    timeseries=X,\n",
    "    geom=geom,\n",
    "    sampling_frequency=fs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.3878893e-07, -1.9197016e-06, -1.8648531e-06, ...,\n",
       "         9.8727514e-07,  5.4848616e-08, -1.0421237e-06],\n",
       "       [ 7.1303202e-07, -4.3878893e-07, -4.9363757e-07, ...,\n",
       "        -1.0969723e-07,  3.8394032e-07,  2.2487934e-06]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recording = st.preprocessing.bandpass_filter(recording, freq_min=300, freq_max=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Documents/nicos_spikesort/kach_dir/'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw_path = ka.store_file(fname  + 'raw.mda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kach_dir_files = ! ls kach_dir\n",
    "if \"geom.csv\" not in kach_dir_files :\n",
    "    ! touch kach_dir/geom.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj = dict(\n",
    "    raw=raw_path,\n",
    "    params=ka.load_object(fname + 'params.json'),\n",
    "    geom=np.genfromtxt(ka.load_file(fname + 'geom.csv'), delimiter=',').tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj['self_reference'] = ka.store_object(obj, basename='{}.json'.format(label))\n",
    "print(obj['self_reference'])\n",
    "with open(output_fname, 'w') as f:\n",
    "    json.dump(obj, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_recording(*, fname, recording, output_fname, label):\n",
    "            raw_path = ka.store_file(fname  + 'raw.mda')\n",
    "            obj = dict(\n",
    "                raw=raw_path,\n",
    "                params=ka.load_object(fname + 'params.json'),\n",
    "                #geom=np.genfromtxt(ka.load_file(fname + 'geom.csv'), delimiter=',').tolist()\n",
    "            )\n",
    "            obj['self_reference'] = ka.store_object(obj, basename='{}.json'.format(label))\n",
    "\n",
    "            with open(output_fname, 'w') as f: json.dump(obj, f, indent=4)\n",
    "            return obj['self_reference']\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device: '/home/jovyan/Documents/nicos_spikesort/kach_dir/tmp/tmpo7lhwjqy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1c72f7f5ede9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecording_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mregister_recording\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrecording\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecording\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_fname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'new_recording.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'new_recording'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-c997f20323fb>\u001b[0m in \u001b[0;36mregister_recording\u001b[0;34m(fname, recording, output_fname, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregister_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecording\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0mraw_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'raw.mda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             obj = dict(\n\u001b[1;32m      4\u001b[0m                 \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'params.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/kachery/core.py\u001b[0m in \u001b[0;36mstore_file\u001b[0;34m(path, basename, git_annex_mode, _no_manifest, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'{}://{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mmanifest_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanifest0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_no_manifest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmanifest_uri\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mmanifest_sha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanifest_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/kachery/core.py\u001b[0m in \u001b[0;36mstore_object\u001b[0;34m(object, basename, indent, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mbasename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplejson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstore_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstore_npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/kachery/core.py\u001b[0m in \u001b[0;36mstore_text\u001b[0;34m(text, basename, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbasename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mbasename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mTemporaryDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmpdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/text.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/kachery/_temporarydirectory.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdirpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/tempfile.py\u001b[0m in \u001b[0;36mmkdtemp\u001b[0;34m(suffix, prefix, dir)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tempfile.mkdtemp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0o700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mcontinue\u001b[0m    \u001b[0;31m# try again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/home/jovyan/Documents/nicos_spikesort/kach_dir/tmp/tmpo7lhwjqy'"
     ]
    }
   ],
   "source": [
    "recording_path =  register_recording( recording=recording, fname=fname, output_fname=fname+'new_recording.json', label='new_recording')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"black\"> Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy dataset courtesy of spikeforest's example \n",
    "#recording_path = 'sha1://961f4a641af64dded4821610189f808f0192de4d/SYNTH_MEAREC_TETRODE/synth_mearec_tetrode_noise10_K10_C4/002_synth.json' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ka.config(fr='default_readonly'):\n",
    "    #with hither.config(cache='default_readwrite'):\n",
    "        with hither.config(container='default'):\n",
    "            result = sorters.spykingcircus.run(\n",
    "                    recording_path=recording_path,\n",
    "                    sorting_out=hither.File()\n",
    "                    )\n",
    "            print(\"recording out path: \", recording_path)\n",
    "            print(\"sorting out path: \",result.outputs.sorting_out)\n",
    "            sorting_path = str(result.outputs.sorting_out)\n",
    "\n",
    "print(result.outputs.sorting_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_out_short = sorting_path[12:-1]\n",
    "\n",
    "print(\"This is the new short path for the sorting: \",sorting_out_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeforest2_utils import AutoRecordingExtractor, AutoSortingExtractor\n",
    "import kachery as ka\n",
    "\n",
    "universal_sorting_path = ka.store_file(sorting_out_short)\n",
    "\n",
    "recording = AutoRecordingExtractor(recording_path, download=False)\n",
    "sorting_true = AutoSortingExtractor(universal_sorting_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can access the recording using the SpikeInterface API\n",
    "# For example, print the electrode locations and unit IDs\n",
    "print(recording.get_channel_locations())\n",
    "print(sorting_true.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_ts = sw.plot_timeseries(recording)\n",
    "    \n",
    "    #does not work w no geom:\n",
    "    #w_el = sw.plot_electrode_geometry(recording)\n",
    "    #pickle.dump(w_el, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "w_sp = sw.plot_spectrum(recording)\n",
    "    \n",
    "w_rs = sw.plot_rasters(sorting_true, sampling_frequency=fs)\n",
    "    \n",
    "w_isi = sw.plot_isi_distribution(sorting_true, sampling_frequency=fs, bins=10, window=1)\n",
    "    \n",
    "w_ach = sw.plot_autocorrelograms(sorting_true, sampling_frequency=fs, bin_size=1, window=10, unit_ids=[1, 2, 4, 5, 8, 10, 7])\n",
    "    \n",
    "w_cch = sw.plot_crosscorrelograms(sorting_true, sampling_frequency=fs, unit_ids=[1, 5, 8], bin_size=0.1, window=5)\n",
    "\n",
    "w_wf = sw.plot_unit_waveforms(recording, sorting_true,unit_ids=sorting_true.get_unit_ids(),  max_spikes_per_unit=100)\n",
    "    \n",
    "w_ampd = sw.plot_amplitudes_distribution(recording, sorting_true, max_spikes_per_unit=300)\n",
    "    \n",
    "w_ampt = sw.plot_amplitudes_timeseries(recording, sorting_true, max_spikes_per_unit=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Curate Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curated_units = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w_wf = sw.plot_unit_waveforms(recording, sorting_true,unit_ids=curated_units,max_channels=1,color='darkgreen', max_spikes_per_unit=300)#,figure=fig)#,axis=)\n",
    "\n",
    "plt.yticks(np.arange(-1.5, 2.0, 1))\n",
    "print(\"Each graph spans 3ms x axis. Y axis is microvolts -- the same as the amplitude distributions in the other graphs\")\n",
    "w_wf = sw.plot_unit_waveforms(recording, sorting_true,unit_ids=[curated_units[1],curated_units[0]],max_channels=1,color='darkgreen', max_spikes_per_unit=300)#,figure=fig)#,axis=)\n",
    "\n",
    "plt.yticks(np.arange(-1.5, 2.0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "\"docker rm\" requires at least 1 argument.\n",
      "See 'docker rm --help'.\n",
      "\n",
      "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Remove one or more containers\n"
     ]
    }
   ],
   "source": [
    "!sudo docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=10):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, frame.filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
