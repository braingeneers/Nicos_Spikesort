{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\" size=7>Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the source code that runs the `spikesort_easy` application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">This code is based on [this repository](https://github.com/flatironinstitute/spikeforest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Siddish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> Finish this notebook so that you can create a functioning application inside the `Welcome to spikesort_easy` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kachery as ka\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "#do things to get braingeneers data\n",
    "#install(\"git+https://github.com/braingeneers/braingeneerspy.git\")\n",
    "#install(\"matplotlib\")\n",
    "import hither_sf as hither\n",
    "from spikeforest2 import sorters\n",
    "import matplotlib\n",
    "import braingeneers.datasets_electrophysiology\n",
    "import spikeinterface.extractors as se #for mda conversion only\n",
    "import spiketoolkit as st\n",
    "import braingeneers\n",
    "from braingeneers import datasets_electrophysiology as ephys\n",
    "import numpy as np\n",
    "import json\n",
    "import spikeforest2_utils\n",
    "from spikeforest2_utils import AutoRecordingExtractor, MdaRecordingExtractor\n",
    "import hither_sf as hither\n",
    "import kachery as ka\n",
    "import io\n",
    "import sys\n",
    "spikeforest2_utils.__version__=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = !ls\n",
    "if \"kach_dir\" not in folders:\n",
    "    !mkdir kach_dir\n",
    "    !touch kach_dir/raw.mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = ! pwd\n",
    "kach_dir = current_dir[0] + \"/kach_dir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Choose Experiment, time range, channels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">choose time range, experiment name, experiment num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.environ['KACHERY_STORAGE_DIR']=kach_dir\n",
    "batch_uuid = '2020-11-27-e-UCSF-axionplate' \n",
    "experiment_num= 9 #arpitha make this a button to choose exp num\n",
    "start = 1 #arpitha, sliders here for start minutes\n",
    "stop = 5 #and end minutes\n",
    "#recording_path = 'sha1://961f4a641af64dded4821610189f808f0192de4d/SYNTH_MEAREC_TETRODE/synth_mearec_tetrode_noise10_K10_C4/002_synth.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view other experiment numbers in the same batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for num in range(100):\n",
    "        print(\"Below is experiment number \", num)\n",
    "        experiment = braingeneers.datasets_electrophysiology.load_experiment(batch_uuid, num)\n",
    "        print(experiment.keys())\n",
    "        experiment[\"notes\"]\n",
    "except:\n",
    "    print(\"these are the first 100 experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">choose channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels=[5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data, time array (seconds), and sampling freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t, fs = ephys.load_blocks(batch_uuid, experiment_num, start=start, stop=stop)\n",
    "\n",
    "X = X.T #spikeinterface wants it MxN (channel number by time)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"this is sampling Freq: \", fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">optionally (ideally): apply geometry for locations of electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_chan = X[selected_channels[0],:]\n",
    "print(\"last_chan shape \", last_chan.shape)\n",
    "print(\"X[0].shape \", X[0].shape)\n",
    "\n",
    "geom = np.zeros(((len(selected_channels)),2)) # initialize recording device geometry to zeros\n",
    "\n",
    "if len(selected_channels)==1:\n",
    "    this_chan = X[selected_channels[0]]\n",
    "    this_chan = np.array([this_chan])\n",
    "    X = this_chan\n",
    "    print(\"1 chan: \", X.shape)\n",
    "    \n",
    "    \n",
    "if len(selected_channels)==2:\n",
    "    X = np.append([X[selected_channels[0]]], [X[selected_channels[1]]], axis=0)\n",
    "    print(\"2 chan: \", X.shape)\n",
    "    geom = np.array([[0.0,0.0],[0.0,1.0]])\n",
    "\n",
    "if len(selected_channels)>2: #PROBLEMATIC\n",
    "    for chan in range(1,len(selected_channels)):\n",
    "        last_chan = np.append([last_chan],[X[selected_channels[chan]]],axis=0)\n",
    "    X = last_chan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape\n",
    "#X[1:10,1:10]\n",
    "print(\"minutes = \", X.shape[1]/fs/60)\n",
    "print(\"expected minutes =\", stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X.shape[0] == 2 :\n",
    "    geom = np.array([[0.0,0.0],[0.0,1.0]])\n",
    "    print(\"only two channels, so Geom always two points 1 unit apart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom.shape #the 2d locations in space of each channel on the recording device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"Recording\" for spikeForest and Filter recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording=se.NumpyRecordingExtractor(\n",
    "    timeseries=X,\n",
    "    geom=geom,\n",
    "    sampling_frequency=fs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recording = st.preprocessing.bandpass_filter(recording, freq_min=300, freq_max=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw_path = ka.store_file(fname  + 'raw.mda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kach_dir_files = ! ls kach_dir\n",
    "if \"geom.csv\" not in kach_dir_files :\n",
    "    ! touch kach_dir/geom.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj = dict(\n",
    "    raw=raw_path,\n",
    "    params=ka.load_object(fname + 'params.json'),\n",
    "    geom=np.genfromtxt(ka.load_file(fname + 'geom.csv'), delimiter=',').tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj['self_reference'] = ka.store_object(obj, basename='{}.json'.format(label))\n",
    "print(obj['self_reference'])\n",
    "with open(output_fname, 'w') as f:\n",
    "    json.dump(obj, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_recording(*, fname, recording, output_fname, label):\n",
    "            raw_path = ka.store_file(fname  + 'raw.mda')\n",
    "            obj = dict(\n",
    "                raw=raw_path,\n",
    "                params=ka.load_object(fname + 'params.json'),\n",
    "                geom=np.genfromtxt(ka.load_file(fname + 'geom.csv'), delimiter=',').tolist()\n",
    "            )\n",
    "            obj['self_reference'] = ka.store_object(obj, basename='{}.json'.format(label))\n",
    "\n",
    "            with open(output_fname, 'w') as f: json.dump(obj, f, indent=4)\n",
    "            return obj['self_reference']\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_path =  register_recording( recording=recording, fname=fname, output_fname=fname+'new_recording.json', label='new_recording')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"black\"> Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy dataset courtesy of spikeforest's example \n",
    "#recording_path = 'sha1://961f4a641af64dded4821610189f808f0192de4d/SYNTH_MEAREC_TETRODE/synth_mearec_tetrode_noise10_K10_C4/002_synth.json' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ka.config(fr='default_readonly'):\n",
    "    #with hither.config(cache='default_readwrite'):\n",
    "        with hither.config(container='default'):\n",
    "            result = sorters.spykingcircus.run(\n",
    "                    recording_path=recording_path,\n",
    "                    sorting_out=hither.File()\n",
    "                    )\n",
    "            print(\"recording out path: \", recording_path)\n",
    "            print(\"sorting out path: \",result.outputs.sorting_out)\n",
    "            sorting_path = str(result.outputs.sorting_out)\n",
    "\n",
    "print(result.outputs.sorting_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_out_short = sorting_path[12:-1]\n",
    "\n",
    "print(\"This is the new short path for the sorting: \",sorting_out_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeforest2_utils import AutoRecordingExtractor, AutoSortingExtractor\n",
    "import kachery as ka\n",
    "\n",
    "universal_sorting_path = ka.store_file(sorting_out_short)\n",
    "\n",
    "recording = AutoRecordingExtractor(recording_path, download=False)\n",
    "sorting_true = AutoSortingExtractor(universal_sorting_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can access the recording using the SpikeInterface API\n",
    "# For example, print the electrode locations and unit IDs\n",
    "print(recording.get_channel_locations())\n",
    "print(sorting_true.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts = sw.plot_timeseries(recording)\n",
    "    \n",
    "    #does not work w no geom:\n",
    "    #w_el = sw.plot_electrode_geometry(recording)\n",
    "    #pickle.dump(w_el, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "w_sp = sw.plot_spectrum(recording)\n",
    "    \n",
    "w_rs = sw.plot_rasters(sorting_true, sampling_frequency=fs)\n",
    "    \n",
    "w_isi = sw.plot_isi_distribution(sorting_true, sampling_frequency=fs, bins=10, window=1)\n",
    "    \n",
    "w_ach = sw.plot_autocorrelograms(sorting_true, sampling_frequency=fs, bin_size=1, window=10, unit_ids=[1, 2, 4, 5, 8, 10, 7])\n",
    "    \n",
    "w_cch = sw.plot_crosscorrelograms(sorting_true, sampling_frequency=fs, unit_ids=[1, 5, 8], bin_size=0.1, window=5)\n",
    "\n",
    "w_wf = sw.plot_unit_waveforms(recording, sorting_true,unit_ids=sorting_true.get_unit_ids(),  max_spikes_per_unit=100)\n",
    "    \n",
    "w_ampd = sw.plot_amplitudes_distribution(recording, sorting_true, max_spikes_per_unit=300)\n",
    "    \n",
    "w_ampt = sw.plot_amplitudes_timeseries(recording, sorting_true, max_spikes_per_unit=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curate Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_units = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w_wf = sw.plot_unit_waveforms(recording, sorting_true,unit_ids=curated_units,max_channels=1,color='darkgreen', max_spikes_per_unit=300)#,figure=fig)#,axis=)\n",
    "\n",
    "plt.yticks(np.arange(-1.5, 2.0, 1))\n",
    "print(\"Each graph spans 3ms x axis. Y axis is microvolts -- the same as the amplitude distributions in the other graphs\")\n",
    "w_wf = sw.plot_unit_waveforms(recording, sorting_true,unit_ids=[curated_units[1],curated_units[0]],max_channels=1,color='darkgreen', max_spikes_per_unit=300)#,figure=fig)#,axis=)\n",
    "\n",
    "plt.yticks(np.arange(-1.5, 2.0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
